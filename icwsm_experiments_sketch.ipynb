{
 "metadata": {
  "name": "",
  "signature": "sha256:7c3d7310624dd4603d7c88e8663e8a2d12d2ff3bdd06b65545e32fe389f2dc23"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Causal inference, potential outcomes, and randomization"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Some introductory stuff that Sean can flesh out"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- Sean can fill this in and shuffle things around. I do like this ICWSM hashtag example though."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- Motivating example: in an observational analysis, people who receive the treatment are generally somewhat different from those who don't. For example, those who have friends tweeting about #icwsm are different from those who do not.\n",
      " - Let's call the outcome for user $i$ exposed to the #icwsm hashtag $Y^{(1)}_i$, and $Y^{(0)}_i$ if they were not exposed."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- Random assignment gives a workaround to the fundamental problem of causality (by linearity of expectation)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "$$\\text{ATE} = \\delta = \\mathbb{E}[Y^{(1)}_i - Y^{(0)}_i] = \\mathbb{E}[Y^{(1)}_i] - \\mathbb{E}[Y^{(0)}_i]$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- This allows us to estimate causal effects from samples among disjoint sets of individuals. The hat means we are estimating something from data, rather than talking about a priori facts about random variables."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "$$\\widehat{\\text{ATE}} = \\frac{1}{N}\\sum_{i \\in T}{Y^{(1)}_i} - \\frac{1}{M}\\sum_{i \\in C}{Y^{(0)}_i}$$"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Measuring treatment effects"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We do not live in a world of facts."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- The variance of the ATE depends on variability under the treatment and control, and how strongly correlated the outcomes are.\n",
      "\n",
      "$$\\text{Var}(Y^{(1)}_i-Y^{(0)}_i) = \\text{Var}(Y^{(0)}_i) + \\text{Var}(Y^{(1)}_i) - 2\\text{Cov}(Y^{(0)}_i, Y^{(1)}_i)$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- The sampling distribution. The world is noisy: we may get different results had different subjects participated in the experiment (or had subjects been assigned differently).  *Not sure exactly how to present this: the latter interpretation falls very clearly from randomization inference, whereas the former makes more sense in the context of bootstrapping*"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- Here is the true standard error of the estimated ATE. The standard error is the standard deviation of your estimated treatment effect. This is how much variation we'd get if we repeated the experiment many times. *The first expression is how they write it in G&G, but I like it more in terms of number of individuals in each condition. What do you think?*"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If you are using randomization inference, there is this 2Cov() due to the fact that there is negative dependence between the units, depending on whether they are observed under the treatment or control. Therefore, we probably won't present it w/ the 2Cov, or with the finite sample size correction."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "$$\\text{SE}(\\widehat{\\text{ATE}}) = \\sqrt{\\frac{1}{N-1}}\\sqrt{\\frac{m}{N-m}\\text{Var}(Y^{(0)}_i) + \\frac{N-m}{m}\\text{Var}(Y^{(1)}_i) + 2\\text{Cov}(Y^{(0)}_i, Y^{(1)}_i)}$$\n",
      "\n",
      "$$\\text{SE}(\\widehat{\\text{ATE}}) = \\sqrt{\\frac{1}{n_0+n_1-1}}\\sqrt{\\frac{n_1}{n_0}\\text{Var}(Y^{(0)}_i) + \\frac{n_0}{n_1}\\text{Var}(Y^{(1)}_i) + 2\\text{Cov}(Y^{(0)}_i, Y^{(1)}_i)}$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This is what we'd present"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "$$\\widehat{\\text{SE}}(\\widehat{\\text{ATE}}) = \\sqrt{\\frac{1}{n_0+n_1}}\\sqrt{\\frac{n_1}{n_0}\\text{Var}(Y^{(0)}_i) + \\frac{n_0}{n_1}\\text{Var}(Y^{(1)}_i)}$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- Observations:\n",
      " - SE decreases with $\\sqrt{N}$\n",
      " - SE is smaller when variances of potential outcomes are smaller\n",
      " - Want $n_0$ and $n_1$ to be similar if the variances are the same.\n",
      " - Want more observations for higher variance conditions"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- This is the true standard error, but we can't actually observe both potential outcomes, or how they are correlated! Need to approximate these somehow."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* The 95% confidence interval is 1.96 times $\\widehat{\\text{SE}}(\\widehat{\\text{ATE}})$. Note that SEs shrink with the square root of the number of observations, so to double the precision of your experiment you need four times the number of subjects."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- Define null hypothesis. ? Allude to randomization inference?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- NHST vs estimaions+CIs.\n",
      "  - Often easy to get statistical significance with big data. Most things have effects!\n",
      "  - Harder to get big effects!\n",
      "  - CIs make uncertainty about an estimate more credible. e.g., 2010 Election experiment: +0.4 percentage point increase, +-0.37 (95%) interval. could be very small or very large effect *eytan is pulling these numbers out of his butt, should verify*\n",
      "  \n",
      "  **should favor reporting CIs!**"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Inference"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here we talk about CIs, p-values, bootstrapping, user-clustered bootstrapping, one-way dependence, multi-way dependence."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- ? p-values and RI?\n",
      "- The bootstrap:\n",
      " - How do you compute SDs of variables without any equations?\n",
      " - Can be thought about in terms of observing or not observing different people\n",
      " - Introduce the online double or nothing bootstrap, plots, give examples\n",
      " - Talk about the idea of multiple observations per user. Explain single-way bootstrap. Can recycle Eytan's slides.\n",
      " - Talk about the idea of having multiple observations per item. Give an example of News articles presented to users in an MTurk experiment. Can recycle Eytan's slides."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}